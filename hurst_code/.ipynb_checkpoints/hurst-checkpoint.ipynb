{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7adc0bd-03f1-4662-aa1a-2e514033047c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.tsa.stattools as ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa7155b-82b4-4fd4-807c-c22a307e4459",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_csv = False\n",
    "s1218 = 1\n",
    "years = 2015 - 1990 + 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb82f05-2dc7-4c7c-8371-576461950756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordenando os melhores pares\n",
    "def top_coint_pairs(data,pvalue_matrix,gamma, alpha, n): \n",
    "#alpha = nivel de significancia para o teste ADF\n",
    "#n = top n ativos com o menor pvalue    \n",
    "    alpha_filter = np.where(pvalues < alpha)\n",
    "    pvalues_f = pvalues[alpha_filter] # pvalores menores que alpha\n",
    "    #print(f\"Alpha filter rows len {len(alpha_filter[0])} | cols len {len(alpha_filter[1])} | value {alpha_filter}\")\n",
    "    #print(f\"pvalues_f len: {np.shape(pvalues_f)} | value: {pvalues_f}\")\n",
    "    stock_a = data.columns[list(alpha_filter)[0]] # relacionando o pvalor com a ação A\n",
    "    stock_b = data.columns[list(alpha_filter)[1]] # relacionando o pvalor com a ação B\n",
    "    gammas_f = gammas[alpha_filter] # relacionando o pvalor com o gamma\n",
    "    N = len(list(alpha_filter[0])) # quantidade de pares cointegrados\n",
    "\n",
    "    d = []\n",
    "    for i in range(N):\n",
    "        pair_dict = {\n",
    "            'Stock A': stock_a[i],\n",
    "            'Stock B': stock_b[i],\n",
    "            'P-Values': pvalues_f[i],\n",
    "            'Gamma': gammas_f[i]\n",
    "        }\n",
    "        #if(i%2000 == 0):\n",
    "        #print(f\"Appending pair dict: {pair_dict}\")\n",
    "        d.append(pair_dict)\n",
    "\n",
    "    return pd.DataFrame(d).sort_values(by=\"P-Values\").iloc[:n,]\n",
    "\n",
    "\n",
    "# Calcula os retornos da carteira e armazenando em um data frame\n",
    "def calculate_profit(pair, spread, threshold, par1, par2, resumo, semester, gamma):\n",
    "    #print(f\"Calculating profits for pair {par1}-{par2}\")\n",
    "    \n",
    "    #print(f\"Spread series: {spread}\")\n",
    "    \n",
    "    date_format = \"%Y-%m-%d\"\n",
    "    \n",
    "    log_ret = spread.diff() # log return eh o incremento\n",
    "    #print(f\"log_ret len: {len(log_ret)} | variable: {log_ret}\")\n",
    "    dias = spread.index\n",
    "    #print(f\"Dias len: {len(dias)} | variable: {dias}\")\n",
    "    z_score = (spread-spread.mean())/spread.std()\n",
    "    z_score.plot()\n",
    "    #print(f\"Z-score index: {z_score.index} | variable: {z_score}\")\n",
    "    portfolio_return = []\n",
    "    pos = 0 # 0: sem posição aberta\n",
    "            # 1: Comprei o meu portfolio h = (1,-gamma)\n",
    "            # -1: Vendi o meu portfolio h = -(1,-gamma)\n",
    "\n",
    "    dias_abertura = []\n",
    "    dias_fechamento = []\n",
    "\n",
    "    count = 0\n",
    "    dia_abertura = 0\n",
    "    dia_fechamento = 0\n",
    "    \n",
    "    closing_threshold = 0.75\n",
    "    \n",
    "    for i in z_score.index:   \n",
    "        if (z_score[i] > threshold) and (pos == 0):\n",
    "            # Posição fechada no par e com sinal short 1st e long 2nd\n",
    "            pos = -1\n",
    "\n",
    "            count += 1\n",
    "            dia_abertura = dias[i - dias[0]]\n",
    "            retornos_op = []\n",
    "\n",
    "\n",
    "        elif (z_score[i] < -threshold)  and (pos == 0):\n",
    "            # Posição fechada no par e com sinal de long 1st e short 2nd \n",
    "            pos = 1            \n",
    "\n",
    "            count += 1\n",
    "            dia_abertura = dias[i - dias[0]]\n",
    "            retornos_op = []\n",
    "\n",
    "        else:\n",
    "            #print(f\"Dia {i} | Pos {pos} | log_ret {log_ret[i]} | S1 return {returns[par1][i]} | S2 return {returns[par2][i]} | Net {pos*(returns[par1][i] - gamma*returns[par2][i])}\")\n",
    "            if (pos == 1) and (z_score[i] < -closing_threshold):\n",
    "                # Posição vendidada aberta no par aberta e sem convergência\n",
    "                portfolio_return.append(log_ret[i]*pos)\n",
    "                retornos_op.append(log_ret[i]*pos)\n",
    "                \n",
    "                Rpair[i-1, pair] = log_ret[i]*pos\n",
    "\n",
    "\n",
    "            elif (pos == 1) and (z_score[i] >= -closing_threshold):\n",
    "                # Posição vendida aberta no par e com sinal de convergência\n",
    "                portfolio_return.append(log_ret[i]*pos)\n",
    "                pos = 0\n",
    "\n",
    "                dia_fechamento = dias[i - dias[0]]\n",
    "                delta_dias = dia_fechamento - dia_abertura\n",
    "                retornos_op.append(log_ret[i]*pos)\n",
    "                retorno_op = pd.Series(retornos_op).sum()\n",
    "\n",
    "                Rpair[i-1, pair] = log_ret[i]*pos\n",
    "                \n",
    "                resumo.append([count, semester, dia_abertura, dia_fechamento, delta_dias, retorno_op, par1, par2, True])\n",
    "\n",
    "            \n",
    "            elif (pos == -1) and (z_score[i] > closing_threshold):\n",
    "                portfolio_return.append(log_ret[i]*pos)\n",
    "                retornos_op.append(log_ret[i]*pos)\n",
    "\n",
    "                Rpair[i-1, pair] = log_ret[i]*pos\n",
    "                \n",
    "\n",
    "            elif (pos == -1) and (z_score[i] <= closing_threshold):\n",
    "                portfolio_return.append(log_ret[i]*pos)\n",
    "                pos = 0\n",
    "\n",
    "                dia_fechamento = dias[i - dias[0]]\n",
    "                delta_dias = dia_fechamento - dia_abertura\n",
    "                retornos_op.append(log_ret[i]*pos)\n",
    "                retorno_op = pd.Series(retornos_op).sum()\n",
    "\n",
    "                Rpair[i-1, pair] = log_ret[i]*pos\n",
    "                \n",
    "                resumo.append([count, semester, dia_abertura, dia_fechamento, delta_dias, retorno_op, par1, par2, True])\n",
    "\n",
    "            else:\n",
    "                # Sem posição aberta e nem sinal de entrada\n",
    "                \n",
    "                if pos != 0:\n",
    "                    dia_fechamento = dias[i - dias[0]]\n",
    "                    delta_dias = dia_fechamento - dia_abertura\n",
    "                    retornos_op.append(log_ret[i]*pos)\n",
    "                    retorno_op = pd.Series(retornos_op).sum()\n",
    "\n",
    "                    Rpair[i-1, pair] = log_ret[i]*pos\n",
    "                    \n",
    "                    resumo.append([count, semester, dia_abertura, dia_fechamento, delta_dias, retorno_op, par1, par2, True])\n",
    "\n",
    "                pos = 0\n",
    "\n",
    "    if pos != 0:\n",
    "        # Operação sem convergência\n",
    "        pos = 0\n",
    "\n",
    "        dia_fechamento = i\n",
    "        delta_dias = dia_fechamento - dia_abertura\n",
    "        retorno_op = pd.Series(retornos_op).sum()\n",
    "\n",
    "        resumo.append([count, semester, dia_abertura, dia_fechamento, delta_dias, retorno_op, par1, par2, False])\n",
    "                \n",
    "    #print(f\"Total return: {sum(pair_returns)} | Pair returns: {pair_returns}\")\n",
    "    #print(f\"Conversão do par: {pos}\")    \n",
    "    total_ret = pd.Series(portfolio_return).sum()\n",
    "\n",
    "    return total_ret, resumo\n",
    "\n",
    "\n",
    "# Calcula o expoente de hurst\n",
    "def get_hurst_exponent(time_series):\n",
    "    \n",
    "    # Definindo o intervalo de taus\n",
    "    max_tau = round(len(time_series)/4)\n",
    "    taus = range(2, max_tau)\n",
    "\n",
    "    # Calculando a variável k\n",
    "    k = [np.std(np.subtract(time_series[tau:], time_series[:-tau])) for tau in taus]\n",
    "    \n",
    "    'To calculate the Hurst exponent, we first calculate the standard deviation of the differences between a series and its lagged version, for a range of possible lags.'\n",
    "\n",
    "    # Calculate the slope of the log plot -> the Hurst Exponent\n",
    "    reg = np.polyfit(np.log(taus), np.log(k), 1)\n",
    "    \n",
    "    'We then estimate the Hurst exponent as the slope of the log-log plot of the number of lags versus the mentioned standard deviations.'\n",
    "\n",
    "    return reg[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7186c7-60dc-4a9c-a2b7-2e4e6038c641",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = pd.read_csv(\"../cointegration_data/Pt_cointegration.csv\")\n",
    "returns = pd.read_csv(\"../cointegration_data/Rt_cointegration.csv\")\n",
    "periods = pd.read_csv(\"../distance_data/Periods.csv\", header=None)\n",
    "ticker2 = pd.read_csv(\"../distance_data/ticker2.csv\", header=None)\n",
    "ticker_b = pd.read_csv(\"../distance_data/ticker_b.csv\", header=None)\n",
    "\n",
    "print(prices)\n",
    "print(returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2999f05c-31a5-423c-978b-4547fd31ea01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversão dos dados para log dos preços\n",
    "log_data = np.log(prices)\n",
    "print(log_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfc114d-22bc-485f-98bf-f160364f77d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_pairs = 20\n",
    "days, num_assets = np.shape(returns)\n",
    "first_traininig = int(periods.iloc[0, 3])\n",
    "Rpair = np.zeros((days, no_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1e932d-96b2-40c3-8216-943830505626",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "resumos = []\n",
    "alpha = 0.05\n",
    "threshold = 1.5\n",
    "\n",
    "read_csv = False\n",
    "\n",
    "past_days=0\n",
    "\n",
    "for big_loop in range(0, int(years * 2 - 2)):\n",
    "    print(f\"Starting period {big_loop} | Past days: {past_days}\")\n",
    "    \n",
    "    twelve_months = int(periods.iloc[big_loop, 3])\n",
    "    six_months = int(periods.iloc[big_loop + 2, 0])\n",
    "    \n",
    "    # Limpeza das ações não listadas no período\n",
    "    listed1 = log_data.iloc[past_days, :] > 0\n",
    "    listed2 = log_data.iloc[past_days+int(twelve_months+six_months*(s1218 == 1))-1, :] > 0\n",
    "    listed = np.multiply(listed1, listed2)\n",
    "    listed_num = np.sum(listed)\n",
    "    #print(f\"Listed stocks for the period: {listed_num}\")\n",
    "    listed_indexes = np.where(listed > 0)[0]\n",
    "    #print(f\"Listed indexes len {np.shape(listed_indexes)} value {listed_indexes}\")\n",
    "    listed_stocks = log_data.columns[listed_indexes]\n",
    "    \n",
    "    #print(f\"First listed stockes len {np.shape(listed_stocks)} value {listed_stocks}\")\n",
    "    \n",
    "    [D, ia, ib] = np.intersect1d(\n",
    "        ticker2.iloc[:, big_loop], ticker2.iloc[:, big_loop+1], return_indices=True)\n",
    "    \n",
    "    ic = np.isin(D, ticker2.iloc[:, big_loop+2])\n",
    "    \n",
    "    #print(f\"ic len: {np.shape(ic)} | variable: {ic}\")\n",
    "    #print(f\"D(ic) len: {np.shape(D[ic])} | variable: {D[ic]}\")\n",
    "    \n",
    "    Dic_unique_sorted, B_idx = np.unique(D[ic], return_index=True)\n",
    "    #print(f\"Dic_unique_sorted len: {np.shape(Dic_unique_sorted)} | variable: {Dic_unique_sorted}\")\n",
    "    \n",
    "    listed_union = np.intersect1d(listed_stocks,Dic_unique_sorted)\n",
    "    #print(f\"Listed union len {np.shape(listed_union)} value {listed_union}\")\n",
    "    \n",
    "    index_listed2 = [log_data.columns.get_loc(i) for i in listed_union if i in log_data]\n",
    "    index_listed2.sort()\n",
    "    #print(f\"Listed union indexes len {np.shape(index_listed2)} value {index_listed2}\")\n",
    "    \n",
    "    if os.path.exists(f\"../cointegration_data/pvalues_semester_{big_loop}.csv\"):\n",
    "        print(\"Reading csv\")\n",
    "        try:\n",
    "            pvalues = np.genfromtxt(f\"../cointegration_data/pvalues_semester_{big_loop}.csv\", delimiter=',')\n",
    "            #pvalues = pd.read_csv(f\"cointegration_data/pvalues_semester_{j}.csv\", header=None, index_col=False)\n",
    "            gammas = np.genfromtxt(f\"../cointegration_data/gammas_semester_{big_loop}.csv\", delimiter=',')\n",
    "            #gammas = pd.read_csv(f\"cointegration_data/gammas_semester_{j}.csv\", header=None, index_col=False)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    else:\n",
    "        print(\"Generating csv\")\n",
    "        pvalues, gammas = find_cointegrated_pairs_mod(log_data.iloc[past_days:(past_days+twelve_months),index_listed2]) # 1 ano de formação e 6 meses de teste\n",
    "        \n",
    "    #pd.DataFrame(pvalues).to_csv(f\"../cointegration_data/pvalues_semester_{big_loop}.csv\", header=None, index=False)\n",
    "    #pd.DataFrame(gammas).to_csv(f\"../cointegration_data/gammas_semester_{big_loop}.csv\", header=None, index=False)\n",
    "    \n",
    "    print(f\"Finished finding cointegrated pairs big_loop {big_loop}\")\n",
    "\n",
    "    try:\n",
    "        coint_pairs_df = top_coint_pairs(log_data.iloc[past_days:(past_days+twelve_months),index_listed2], pvalues, gammas, alpha, no_pairs)\n",
    "        print(f\"Found top cointegrated pairs big_loop {big_loop}\")\n",
    "        #print(f\"coint_pairs_df len: {np.shape(coint_pairs_df)} | value: {coint_pairs_df}\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"Exception ao achar top pares cointegrados\")\n",
    "        continue\n",
    "        \n",
    "    for i in range(0,coint_pairs_df.shape[0]):\n",
    "        #print(f\"Pair: {coint_pairs_df.iloc[i,:]}\")\n",
    "        \n",
    "        S1_name = coint_pairs_df.iloc[i, 0]\n",
    "        S2_name = coint_pairs_df.iloc[i, 1]\n",
    "        gamma_1_2 = coint_pairs_df.iloc[i, 3]\n",
    "\n",
    "        S1 = log_data[S1_name].iloc[(past_days+twelve_months):(past_days+twelve_months+six_months)] # periodo de teste\n",
    "        S2 = log_data[S2_name].iloc[(past_days+twelve_months):(past_days+twelve_months+six_months)] # periodo de teste\n",
    "\n",
    "        # Spread\n",
    "        spread = S1 - gamma_1_2*S2\n",
    "        #print(f\"Spread series: {spread}\")\n",
    "        # Pegando o resultado da estratégia\n",
    "        ret, resumos = calculate_profit(i, spread, threshold, S1_name, S2_name, resumos, big_loop, gamma_1_2)\n",
    "        \n",
    "    past_days = past_days + periods.iloc[big_loop, 0]\n",
    "    \n",
    "    \n",
    "cols = ['Operação', 'Semestre', 'Abertura', 'Fechamento', 'Dias', 'Retorno total', 'Ticker 1', 'Ticker 2', 'Converged']\n",
    "df = pd.DataFrame(resumos, columns = cols)\n",
    "df['Index'] = df['Ticker 1'].astype(str) + '-' + df['Ticker 2'].astype(str) + '-' + df['Operação'].astype(str)\n",
    "df['Retorno total - exp'] = np.exp(df['Retorno total'])\n",
    "df.to_csv(\"../hurst_results/operations_test.csv\", sep=',', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b3c45d-d4bc-4370-842e-474b385bc621",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(Rpair).to_csv(\"../hurst_results/Rpair_test.csv\", header=None, index=False)\n",
    "daily_returns = np.sum(Rpair, axis=1)\n",
    "pd.DataFrame(daily_returns).to_csv(\"../hurst_results/daily_returns_test.csv\", header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5a502b-0884-4f58-8e0b-7a48ec1d37ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
